{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'d:\\\\HuggingFace'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\r\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['TRANSFORMERS_CACHE'] = 'd:\\\\HuggingFace\\\\cache\\\\'\r\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'd:/HuggingFace/cache/huggingface/transformers/'\r\n",
    "os.environ['HF_HOME'] = 'd:/HuggingFace/cache/huggingface/transformers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'d:/HuggingFace/cache/huggingface/transformers/'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TRANSFORMERS_CACHE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (d:\\HuggingFace\\cache\\huggingface\\transformers\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 18.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\",\"mrpc\")\r\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n 'label': 1,\n 'idx': 0}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\r\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'sentence1': Value(dtype='string', id=None),\n 'sentence2': Value(dtype='string', id=None),\n 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], id=None),\n 'idx': Value(dtype='int32', id=None)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'sentence1': 'However , EPA officials would not confirm the 20 percent figure .',\n 'sentence2': 'Only in the past few weeks have officials settled on the 20 percent figure .',\n 'label': 0,\n 'idx': 812}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"validation\"][87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'sentence1': 'Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .',\n 'sentence2': 'Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .',\n 'label': 0,\n 'idx': 16}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the tokenize with some inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 7.02kB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:01<00:00, 192kB/s]\n",
      "Downloading: 100%|██████████| 455k/455k [00:01<00:00, 239kB/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\r\n",
    "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, the above won't work as the model expects two sequences as a pair. Tokenizer can handle pairs of sentences as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 6251, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\",\"This is the second sentence\")\r\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n 'this',\n 'is',\n 'the',\n 'first',\n 'sentence',\n '.',\n '[SEP]',\n 'this',\n 'is',\n 'the',\n 'second',\n 'sentence',\n '[SEP]']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the above we can see how the tokenizer handles the pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This will work but will not be efficient in terms of memory and we have to deal with each type of dataset.\r\n",
    "### We also have to do any further processing separately as needed\r\n",
    "'''\r\n",
    "tokenized_dataset = tokenizer(\r\n",
    "    raw_datasets[\"train\"][\"sentence1\"],\r\n",
    "    raw_datasets[\"train\"][\"sentence2\"],\r\n",
    "    padding=True,\r\n",
    "    truncation=True\r\n",
    ")\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instead, we will create a function that can work with any element in our dataset dictionary and can be modified\r\n",
    "\r\n",
    "# We also skip padding as padding for the whole dataset is inefficient - we will use dynamic padding\r\n",
    "\r\n",
    "def tokenize_function(example):\r\n",
    "    return tokenizer(example[\"sentence1\"],example[\"sentence1\"],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.94ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.25ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.85ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1725\n    })\n})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched=True in our call to map so the function is applied to multiple elements of our dataset at once, \r\n",
    "# and not on each element separately. This allows for faster preprocessing. \r\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function,batched=True)\r\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[49, 53, 45, 81, 59, 41, 61, 29]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test the collator\r\n",
    "\r\n",
    "samples = tokenized_datasets[\"train\"][:8]\r\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\r\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': TensorShape([8, 81]),\n 'token_type_ids': TensorShape([8, 81]),\n 'attention_mask': TensorShape([8, 81]),\n 'labels': TensorShape([8])}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(samples)\r\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the longest sequence was of size 81, the tensors are of shape 81 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's use this with our tokenized datasets. \r\n",
    "### To create the batches, we can use the to_tf_dataset method which can take an optional collation method\r\n",
    "### We can take the datasets here, directly to our model\r\n",
    "\r\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\r\n",
    "    columns=['attention_mask','input_ids', 'token_type_ids'],\r\n",
    "    label_cols=[\"labels\"],\r\n",
    "    shuffle=True,\r\n",
    "    collate_fn=data_collator,\r\n",
    "    batch_size=8\r\n",
    ")\r\n",
    "\r\n",
    "tf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\r\n",
    "    columns=['attention_mask','input_ids', 'token_type_ids'],\r\n",
    "    label_cols=[\"labels\"],\r\n",
    "    shuffle=True,\r\n",
    "    collate_fn=data_collator,\r\n",
    "    batch_size=8\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 511M/511M [05:07<00:00, 1.74MB/s]\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since Bert wasn't trained for classification task, the head of the model has to be discarded and a new suitable head for sequence classification is inserted. The above warning mentions that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 165s 317ms/step - loss: 0.6938 - accuracy: 0.6239 - val_loss: 0.6317 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1ef8d313370>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\r\n",
    "    optimizer=\"adam\",\r\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "    metrics = [\"accuracy\"]\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    tf_train_dataset,\r\n",
    "    validation_data=tf_validation_dataset\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\r\n",
    "num_epochs = 3\r\n",
    "\r\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\r\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\r\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\r\n",
    "\r\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\r\n",
    "\r\n",
    "lr_scheduler = PolynomialDecay(\r\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps = num_train_steps\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "458/458 [==============================] - 160s 312ms/step - loss: 0.6278 - accuracy: 0.6739 - val_loss: 0.6001 - val_accuracy: 0.6985\n",
      "Epoch 2/3\n",
      "458/458 [==============================] - 156s 340ms/step - loss: 0.5609 - accuracy: 0.7066 - val_loss: 0.5805 - val_accuracy: 0.7010\n",
      "Epoch 3/3\n",
      "458/458 [==============================] - 190s 414ms/step - loss: 0.3187 - accuracy: 0.8701 - val_loss: 0.8246 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1efba11dc40>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\r\n",
    "    optimizer=opt,\r\n",
    "    loss = loss,\r\n",
    "    metrics = [\"accuracy\"]\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    tf_train_dataset,\r\n",
    "    validation_data=tf_validation_dataset,\r\n",
    "    epochs = 3\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tf_validation_dataset)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = tf.nn.softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "class_preds = np.argmax(preds, axis=1)\r\n",
    "print(preds.shape, class_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 5.76kB [00:00, 1.46MB/s]                   \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'accuracy': 0.6397058823529411, 'f1': 0.7617504051863857}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\r\n",
    "\r\n",
    "metric = load_metric(\"glue\", \"mrpc\")\r\n",
    "metric.compute(predictions=class_preds, references=raw_datasets[\"validation\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit",
   "name": "python393jvsc74a57bd0e051af7dc46e92d929adeba82ac9f84b768f57dc1a33fed67bbaf98fd32ec763"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}